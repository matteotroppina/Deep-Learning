{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e4c3b4-2b77-407a-a587-b15b22dc8fc6",
   "metadata": {},
   "source": [
    "# Convergence Rate and Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dcd62e-e682-4258-ba69-39c9398b7973",
   "metadata": {},
   "source": [
    "## 1. Convergence Rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d7b9f-4dfb-4d5d-8d52-79301f12a82d",
   "metadata": {},
   "source": [
    "Gradient Descent algorithm:\n",
    "\n",
    "$x_{i+1} = x_{i} - \\eta \\cdot \\frac{\\partial L}{\\partial x}$\n",
    "\n",
    "$x$ = optimization variable\n",
    "<br> $x_{0}$ = starting point\n",
    "<br> $L$ = loss function\n",
    "\n",
    "Convergence rate:\n",
    "\n",
    "$\\left\\| x_{i+1} - x_{*} \\right\\| \\leq c \\cdot \\left\\| x_i - x_{*} \\right\\|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33faeb8e-b14c-46c5-9d23-13b1a323b6ae",
   "metadata": {},
   "source": [
    "### a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f3a6a-ead9-4aaf-ac5a-c330bc5b0f8a",
   "metadata": {},
   "source": [
    "Given loss function $L(x) = ax^2, \\quad  a>0$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x} = 2ax \\quad \\rightarrow \\quad x_{i+1} = x_{i} - \\eta \\cdot 2ax_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb82e0-cc11-4647-9b3e-0404a37f8104",
   "metadata": {},
   "source": [
    "Convergence of the algorithm:\n",
    "<br> Assuming $x_{*} = 0$ :\n",
    "\n",
    "$\\|x_{i+1} - 0\\| \\leq c \\cdot \\|x_{i} - 0\\|$\n",
    "<br> $\\|x_{i+1}\\| \\leq c \\cdot \\|x_{i}\\|$\n",
    "\n",
    "$\\|x_{i} - \\eta \\cdot 2ax_{i}\\| \\leq c \\cdot \\|x_{i}\\| \\quad \\rightarrow \\quad |1 - 2a \\cdot \\eta| \\cdot \\|x_{i}\\|\\leq c \\cdot \\|x_{i}\\|$\n",
    "\n",
    "\\begin{flalign*}\n",
    "&\\left\\{\n",
    "\\begin{aligned}\n",
    "c &= 1 - 2a \\cdot \\eta \\\\\n",
    "0 &\\leq c < 1\n",
    "\\end{aligned}\n",
    "\\right. &\n",
    "\\end{flalign*}\n",
    "\n",
    "$ 0 \\leq 1 - 2a \\cdot \\eta < 1 \\quad \\rightarrow \\quad \\frac {1}{2a} \\leq -\\eta < 0 \\quad \\rightarrow \\quad 0 \\leq \\eta < \\frac {1}{2a}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44da8dad-3884-4cf4-a78e-1c2c9ec2e177",
   "metadata": {},
   "source": [
    "Best convergence rate:\n",
    "<br> the best rate of convergence is obtained minimizing  $\\quad c = 1 - 2a \\cdot \\eta \\quad $  which translates in maximizing $\\eta$ in the interval $\\quad 0 \\leq \\eta < \\frac {1}{2a}$\n",
    "\n",
    "For the choice $\\quad \\eta = \\frac {1}{2a} \\quad \\rightarrow \\quad c = 0 \\quad$ as the best convergence rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fdc355-87f7-40fe-8d2e-e97aab82a69e",
   "metadata": {},
   "source": [
    "### b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8084ef-1780-4cb4-9489-dc25bf16924b",
   "metadata": {},
   "source": [
    "Given loss function $L(x_{1}, x_{2}) = ax_1^2 + bx_2^2, \\quad 0 < a < b$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_1} = 2ax_1 \\quad \\rightarrow \\quad x_{1}^{i+1} = x_{1}^{i} - \\eta \\cdot 2ax_{1}^{i}$\n",
    "<br> $\\frac{\\partial L}{\\partial x_2} = 2bx_2 \\quad \\rightarrow \\quad x_{2}^{i+1} = x_{2}^{i} - \\eta \\cdot 2bx_{2}^{i}$\n",
    "\n",
    "Convergence of the algorithm:\n",
    "<br> Assuming $x_{*} = [0,0]$ :\n",
    "\n",
    "$\\|x_{i+1} - 0\\| \\leq c \\cdot \\|x_{i} - 0\\|$\n",
    "<br> $\\|x_{i+1}\\| \\leq c \\cdot \\|x_{i}\\|$\n",
    "\n",
    "\\begin{flalign*}\n",
    "&\\left\\{\n",
    "\\begin{aligned}\n",
    "&\\|x_{1}^{i+1} - \\eta \\cdot 2ax_{1}^{i}\\| \\leq c \\cdot \\|x_{1}^{i}\\| \\quad &\\rightarrow \\quad &|1 - 2a \\cdot \\eta| \\cdot \\|x_{1}^{i}\\|\\leq c \\cdot \\|x_{1}^{i}\\| \\quad &\\rightarrow \\quad &c = 1 - 2a \\cdot \\eta\\\\\n",
    "&\\|x_{2}^{i+1} - \\eta \\cdot 2bx_{2}^{i}\\| \\leq c \\cdot \\|x_{2}^{i}\\| \\quad &\\rightarrow \\quad &|1 - 2b \\cdot \\eta| \\cdot \\|x_{2}^{i}\\|\\leq c \\cdot \\|x_{2}^{i}\\| \\quad &\\rightarrow \\quad &c = 1 - 2b \\cdot \\eta\\\\\n",
    "\\end{aligned}\n",
    "\\right. &\n",
    "\\end{flalign*}\n",
    "\n",
    "\\begin{flalign*}\n",
    "&\\left\\{\n",
    "\\begin{aligned}\n",
    "&c = 1 - 2a \\cdot \\eta\\\\\n",
    "&c = 1 - 2b \\cdot \\eta\\\\\n",
    "&0 \\leq c < 1\\\\\n",
    "&0 < a < b\n",
    "\\end{aligned}\n",
    "\\right. &\n",
    "\\end{flalign*}\n",
    "\n",
    "\\begin{flalign*}\n",
    "&\\left\\{\n",
    "\\begin{aligned}\n",
    "&0 \\leq 1 - 2a \\cdot \\eta  < 1 \\quad &\\rightarrow \\quad &\\frac {1}{2a} \\leq -\\eta < 0 \\quad &\\rightarrow \\quad 0 \\leq \\eta < \\frac {1}{2a}\\\\\n",
    "&0 \\leq 1 - 2b \\cdot \\eta  < 1 \\quad &\\rightarrow \\quad &\\frac {1}{2b} \\leq -\\eta < 0 \\quad &\\rightarrow \\quad 0 \\leq \\eta < \\frac {1}{2b}\\\\\n",
    "\\end{aligned}\n",
    "\\right. &\n",
    "\\end{flalign*}\n",
    "\n",
    "Best convergence rate:\n",
    "<br> the best rate of convergence is obtained minimizing  \n",
    "\\begin{flalign*}\n",
    "&\\left\\{\n",
    "\\begin{aligned}\n",
    "&c = 1 - 2a \\cdot \\eta\\\\\n",
    "&c = 1 - 2b \\cdot \\eta\\\\\n",
    "\\end{aligned}\n",
    "\\right. &\n",
    "\\end{flalign*}\n",
    "\n",
    "since $b > a$ this translates in maximizing $\\eta$ in the interval $\\quad 0 \\leq \\eta < \\frac {1}{2a}$\n",
    "\n",
    "For the choice $\\quad \\eta = \\frac {1}{2a} \\quad \\rightarrow \\quad c = 0 \\quad$ as the best convergence rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4bd2e1-1ea7-47bb-a6c9-31727a7c5f12",
   "metadata": {},
   "source": [
    "## 2. Gradient Descent and its Acceleration with Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17fa441-9461-4522-a4d2-c8f05258d72d",
   "metadata": {},
   "source": [
    "Gradient Descent + acceleration with Momentum algorithm:\n",
    "\n",
    "\\begin{flalign*}\n",
    "&\\left\\{\n",
    "\\begin{aligned}\n",
    "&v_{0} = 0 \\\\\n",
    "&v_{i+1} = m \\cdot v_{i} - \\eta \\cdot \\frac{\\partial L}{\\partial x} \\\\\n",
    "&x_{i+1} = x_{i} + v_{i+1}\n",
    "\\end{aligned}\n",
    "\\right. &\n",
    "\\end{flalign*}\n",
    "\n",
    "$m$ = momentum parameter, $\\quad 0 < m < 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c95fe-bc6d-471d-94b9-c755ba2cc5ba",
   "metadata": {},
   "source": [
    "Given loss function $L(x_{1}, x_{2}) = x_1^2 + 4 \\cdot x_2^2, \\quad 0 < a < b$\n",
    "\n",
    "-two trajectories using Gradient Descent\n",
    "<br>-one trajectory using Gradient Descent with momentum\n",
    "\n",
    "$A \\quad \\rightarrow \\quad x_{0} = (-1,-1)$\n",
    "<br> $B \\quad \\rightarrow \\quad x_{0} = (-1,0.5)$\n",
    "<br> $C \\quad \\rightarrow \\quad x_{0} = (1,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391294c4-4ca6-45c7-b15c-ca292ae14685",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b7eb7-6210-4fc0-8cb9-e8d953f24201",
   "metadata": {},
   "source": [
    "For the momentum algorithm:\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x} = (2x_{1}, 8x_{2})$\n",
    "\n",
    "\\begin{flalign*}\n",
    "&\\left\\{\n",
    "\\begin{aligned}\n",
    "A \\quad \\rightarrow \\quad &x_{1} = (-0.9,-0.5) &\\rightarrow \\quad &v_{1} = -\\eta \\cdot (-2,-8) &\\rightarrow \\quad &x_{2} = (-0.9,-0.5) - m \\cdot \\eta \\cdot (-2,-8) - \\eta \\cdot (-1.8, -4)\\\\\n",
    "B \\quad \\rightarrow \\quad &x_{1} = (-0.75,0) &\\rightarrow \\quad  &v_{1} = -\\eta \\cdot (-2,4) &\\rightarrow \\quad &x_{2} = (-0.75,0) - m \\cdot \\eta \\cdot (-2,4) - \\eta \\cdot (1.5, 0)\\\\\n",
    "C \\quad \\rightarrow \\quad &x_{1} = (0.6,-0.6) &\\rightarrow \\quad &v_{1} = -\\eta \\cdot (2,8) &\\rightarrow \\quad &x_{2} = (0.6,-0.6) - m \\cdot \\eta \\cdot (2,8) - \\eta \\cdot (1.2, -4.8) = [0.6 - \\eta \\cdot(2m + 1.2), -0.6 \\\\\n",
    "\\end{aligned}\n",
    "\\right. &\n",
    "\\end{flalign*}\n",
    "\n",
    "$A \\rightarrow$ smoother trajectory towards the minimum\n",
    "<br> $B \\rightarrow$ from the plot can be seen that the $x_{2}$ component settles to zero after the first iteration. From the computation of $x_{2}$ for B we can see that this condition is achieved if and only if $m =0$\n",
    "<br >$C \\rightarrow$ presents oscillations towards the minimum, no smooth\n",
    "\n",
    "Conclusion:\n",
    "<br> $A \\rightarrow$ Gradient Descent + momentum\n",
    "<br> $B \\rightarrow$ Gradient Descent\n",
    "<br> $C \\rightarrow$ Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae865a0-3c48-4dcc-96d6-64ea507603b7",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2864b-701d-4ed4-adf6-5950a4904e94",
   "metadata": {},
   "source": [
    "$v_{0} = 0$\n",
    "\\begin{flalign*}\n",
    "&\\left\\{\n",
    "\\begin{aligned}\n",
    "A \\quad \\rightarrow \\quad &x_{0} = (-1,-1) &\\rightarrow \\quad &x_{1} = (-0.9, -0.5) &= (-1,-1) - \\eta_{A} \\cdot (-2, -8) \\quad &\\rightarrow \\quad -0.5 = -1 - \\eta_{A} \\cdot (-8) \\quad &\\rightarrow \\quad &\\eta_{A} = 0.0625 \\\\\n",
    "B \\quad \\rightarrow \\quad &x_{0} = (-1,0.5) &\\rightarrow \\quad &x_{1} = (-0.75,0) &= (-1,0.5)- \\eta_{B} \\cdot (-2, 4) \\quad &\\rightarrow \\quad 0 = 0.5 - \\eta_{B} \\cdot 4 \\quad &\\rightarrow \\quad &\\eta_{B} =  0.125\\\\\n",
    "C \\quad \\rightarrow \\quad &x_{0} = (0.6,-0.6) &\\rightarrow \\quad &x_{1} = (0.6,-0.6) &= (1,1)- \\eta_{C} \\cdot (2, 8) \\quad &\\rightarrow \\quad -0.6 = 1 - \\eta_{C} \\cdot 8 \\quad &\\rightarrow \\quad &\\eta_{C} =  0.2\\\\\n",
    "\\end{aligned}\n",
    "\\right. &\n",
    "\\end{flalign*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1819f62b-85cf-48fd-931d-7cf423a1d388",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f5bf1-1785-4d36-8934-918237d018ef",
   "metadata": {},
   "source": [
    "Gradient Descent + momentum (A):\n",
    "\n",
    "\\begin{flalign*}\n",
    "&\\left\\{\n",
    "\\begin{aligned}\n",
    "&x_{1} = (-0.9,-0.5)\\\\\n",
    "&v_{1} = -\\eta \\cdot (-2,-8)\\\\\n",
    "&\\eta_{A} = 0.0625\n",
    "\\end{aligned}\n",
    "\\right. &\n",
    "\\end{flalign*}\n",
    "\n",
    "$x_{2} = (-0.7, 0.1) = (-0.9,-0.5) - m \\cdot \\eta \\cdot (-2,-8) - 0.0625 \\cdot (-1.8, -4) \\quad \\rightarrow \\quad 0.6 = 8 \\cdot m \\cdot \\eta_{A} + 4 \\cdot \\eta_{A} \\quad \\rightarrow \\quad m = 0.7$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
